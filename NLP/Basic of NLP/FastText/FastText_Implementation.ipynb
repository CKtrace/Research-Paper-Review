{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e84242-000b-4b0f-af0f-841151676ac0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20867690-cc76-4a8f-be61-bc57d65324b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96781bc4-4d97-4518-aa42-b50c480e9be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('This', 'is'),\n",
       " ('as', 'you'),\n",
       " ('is', 'test'),\n",
       " ('test', 'as'),\n",
       " ('you', 'know')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['This', 'is', 'test', 'as', 'you', 'know']\n",
    "n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e6b9bc-5063-440a-b61a-9189cace8c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'test',\n",
       " 'as',\n",
       " 'you',\n",
       " 'know',\n",
       " 'as you',\n",
       " 'test as',\n",
       " 'you know',\n",
       " 'This is',\n",
       " 'is test']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigrams(['This', 'is', 'test', 'as', 'you', 'know'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb557e8-ab7a-440c-bd3f-55360c70aa7a",
   "metadata": {},
   "source": [
    "## FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e958f8-24c6-4715-8405-3f3f5f0b7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, word_embeddings, embedding_size, hidden_size, output_size):\n",
    "        super(FastText, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embddings(x).permute(1, 0, 2)\n",
    "        x = self.fc1(x.mean(1))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_fine",
   "language": "python",
   "name": "llm_fine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
