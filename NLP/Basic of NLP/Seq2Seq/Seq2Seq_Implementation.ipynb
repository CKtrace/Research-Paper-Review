{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457787e8-8de1-490a-973b-a6f2f93ebb43",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e109845-d652-48c1-aa92-8c1f8f15f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b21472-28da-4aa4-b72b-d5857a78d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30000\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "\n",
    "    return sent\n",
    "\n",
    "def load_preprocessed_data():\n",
    "  encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "  with open(\"fra.txt\", \"rt\", encoding='UTF8') as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "      # source 데이터와 target 데이터 분리\n",
    "      src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "      # source 데이터 전처리\n",
    "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "      # target 데이터 전처리\n",
    "      tar_line = preprocess_sentence(tar_line)\n",
    "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "      encoder_input.append(src_line)\n",
    "      decoder_input.append(tar_line_in)\n",
    "      decoder_target.append(tar_line_out)\n",
    "\n",
    "      if i == num_samples - 1:\n",
    "        break\n",
    "\n",
    "  return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37e2aa83-509f-48fa-a547-7f157f40baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing Eng Sen : Have you had dinner?\n",
      "After Preprocessing Eng Sen : have you had dinner ?\n",
      "Before Preprocessing Fra Sen : Avez-vous déjà diné?\n",
      "After Preprocessing Fra Sen : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('Before Preprocessing Eng Sen :', en_sent)\n",
    "print('After Preprocessing Eng Sen :',preprocess_sentence(en_sent))\n",
    "print('Before Preprocessing Fra Sen :', fr_sent)\n",
    "print('After Preprocessing Fra Sen :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65366391-72bf-4c15-8206-247cc14473dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!']]\n",
      "[['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:3])\n",
    "print(sents_fra_in[:3])\n",
    "print(sents_fra_out[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9113085d-6ba6-4a3a-87d8-6388db05f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sents):\n",
    "  word_list = []\n",
    "\n",
    "  for sent in sents:\n",
    "      for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "  word_counts = Counter(word_list)\n",
    "  vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "  word_to_index = {}\n",
    "  word_to_index['<PAD>'] = 0\n",
    "  word_to_index['<UNK>'] = 1\n",
    "\n",
    "  for index, word in enumerate(vocab) :\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "  return word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb98b56-1970-42ea-892b-ca952f1fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG Word Size : 4287, FRA Word Size : 7476\n"
     ]
    }
   ],
   "source": [
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"ENG Word Size : {:d}, FRA Word Size : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d0f2ce3-26b0-4c8d-9d0e-8f5ec5bc2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tqdm(sents):\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e48f8f-14ae-4426-b158-f16dd1839fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [00:00<00:00, 1303131.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [00:00<00:00, 288201.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [00:00<00:00, 1152861.97it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54250e3b-40a9-4c9b-9132-b99cd71eb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "961a2543-5494-4b8c-a8ce-8aff056f5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbff9a00-45e2-4535-8f37-581365b718c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 7), (30000, 16), (30000, 16))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape, decoder_input.shape, decoder_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b07cf6d6-d48c-4915-a502-eef5d03c87fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sequence : [27798  3040 28667 ... 22736  3240  9997]\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('Random Sequence :',indices)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d0ac88b-48bb-4f10-99a3-90d91a413c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa040255-87a9-4cbe-94b8-9bee849007fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'had', 'fun', 'today', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'je', 'me', 'suis', 'bien', 'amuse', 'aujourd', 'hui', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['je', 'me', 'suis', 'bien', 'amuse', 'aujourd', 'hui', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[20997]])\n",
    "print([index_to_tar[word] for word in decoder_input[20997]])\n",
    "print([index_to_tar[word] for word in decoder_target[20997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6de3e70f-ef1a-414d-849a-10ff63998e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = int(num_samples * 0.1)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c5f40-2a25-4163-bd1b-ece4093e4a35",
   "metadata": {},
   "source": [
    "# Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57975cd5-23a2-49f6-996b-d7464df400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03e6082c-d68d-4332-980f-6c030126be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0de4db8c-33c1-4b94-8b8f-b420e54ba531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        output, _, _ = self.decoder(trg, hidden, cell)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1cd7b81-ab87-4d3c-8d06-1d8639160072",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "391b47ef-8078-43c1-ba5b-64c597f7870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4287, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7476, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7476, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da8b679d-fa00-4ce2-b0b0-1f1770b3acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "            \n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16dbecd6-32f9-4f97-84f6-f5c97ce749ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccab1f2c-d031-4a14-ac74-032cc5deee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc3c8e45-d27a-4979-90ee-95634bf80a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4287, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7476, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7476, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "269fb6a9-141e-4186-a988-ae549bf982e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 3.0362 | Train Acc: 0.5158 | Valid Loss: 3.1349 | Valid Acc: 0.5129\n",
      "Validation loss improved from inf to 3.1349.\n",
      "Epoch: 2/30 | Train Loss: 2.3663 | Train Acc: 0.5938 | Valid Loss: 2.5737 | Valid Acc: 0.5842\n",
      "Validation loss improved from 3.1349 to 2.5737.\n",
      "Epoch: 3/30 | Train Loss: 1.9521 | Train Acc: 0.6357 | Valid Loss: 2.2783 | Valid Acc: 0.6200\n",
      "Validation loss improved from 2.5737 to 2.2783.\n",
      "Epoch: 4/30 | Train Loss: 1.6364 | Train Acc: 0.6727 | Valid Loss: 2.0837 | Valid Acc: 0.6400\n",
      "Validation loss improved from 2.2783 to 2.0837.\n",
      "Epoch: 5/30 | Train Loss: 1.3825 | Train Acc: 0.7063 | Valid Loss: 1.9399 | Valid Acc: 0.6592\n",
      "Validation loss improved from 2.0837 to 1.9399.\n",
      "Epoch: 6/30 | Train Loss: 1.1646 | Train Acc: 0.7444 | Valid Loss: 1.8242 | Valid Acc: 0.6723\n",
      "Validation loss improved from 1.9399 to 1.8242.\n",
      "Epoch: 7/30 | Train Loss: 0.9765 | Train Acc: 0.7779 | Valid Loss: 1.7301 | Valid Acc: 0.6848\n",
      "Validation loss improved from 1.8242 to 1.7301.\n",
      "Epoch: 8/30 | Train Loss: 0.8154 | Train Acc: 0.8131 | Valid Loss: 1.6652 | Valid Acc: 0.6963\n",
      "Validation loss improved from 1.7301 to 1.6652.\n",
      "Epoch: 9/30 | Train Loss: 0.6823 | Train Acc: 0.8387 | Valid Loss: 1.6178 | Valid Acc: 0.7028\n",
      "Validation loss improved from 1.6652 to 1.6178.\n",
      "Epoch: 10/30 | Train Loss: 0.5710 | Train Acc: 0.8651 | Valid Loss: 1.5719 | Valid Acc: 0.7111\n",
      "Validation loss improved from 1.6178 to 1.5719.\n",
      "Epoch: 11/30 | Train Loss: 0.4801 | Train Acc: 0.8828 | Valid Loss: 1.5535 | Valid Acc: 0.7127\n",
      "Validation loss improved from 1.5719 to 1.5535.\n",
      "Epoch: 12/30 | Train Loss: 0.4091 | Train Acc: 0.8972 | Valid Loss: 1.5385 | Valid Acc: 0.7165\n",
      "Validation loss improved from 1.5535 to 1.5385.\n",
      "Epoch: 13/30 | Train Loss: 0.3586 | Train Acc: 0.9064 | Valid Loss: 1.5292 | Valid Acc: 0.7177\n",
      "Validation loss improved from 1.5385 to 1.5292.\n",
      "Epoch: 14/30 | Train Loss: 0.3159 | Train Acc: 0.9129 | Valid Loss: 1.5308 | Valid Acc: 0.7182\n",
      "Epoch: 15/30 | Train Loss: 0.2821 | Train Acc: 0.9187 | Valid Loss: 1.5393 | Valid Acc: 0.7201\n",
      "Epoch: 16/30 | Train Loss: 0.2569 | Train Acc: 0.9218 | Valid Loss: 1.5418 | Valid Acc: 0.7202\n",
      "Epoch: 17/30 | Train Loss: 0.2360 | Train Acc: 0.9249 | Valid Loss: 1.5524 | Valid Acc: 0.7195\n",
      "Epoch: 18/30 | Train Loss: 0.2217 | Train Acc: 0.9264 | Valid Loss: 1.5684 | Valid Acc: 0.7211\n",
      "Epoch: 19/30 | Train Loss: 0.2087 | Train Acc: 0.9282 | Valid Loss: 1.5740 | Valid Acc: 0.7221\n",
      "Epoch: 20/30 | Train Loss: 0.1970 | Train Acc: 0.9294 | Valid Loss: 1.5814 | Valid Acc: 0.7180\n",
      "Epoch: 21/30 | Train Loss: 0.1905 | Train Acc: 0.9303 | Valid Loss: 1.6025 | Valid Acc: 0.7213\n",
      "Epoch: 22/30 | Train Loss: 0.1854 | Train Acc: 0.9301 | Valid Loss: 1.6095 | Valid Acc: 0.7202\n",
      "Epoch: 23/30 | Train Loss: 0.1788 | Train Acc: 0.9308 | Valid Loss: 1.6210 | Valid Acc: 0.7223\n",
      "Epoch: 24/30 | Train Loss: 0.1728 | Train Acc: 0.9315 | Valid Loss: 1.6195 | Valid Acc: 0.7220\n",
      "Epoch: 25/30 | Train Loss: 0.1703 | Train Acc: 0.9314 | Valid Loss: 1.6312 | Valid Acc: 0.7218\n",
      "Epoch: 26/30 | Train Loss: 0.1651 | Train Acc: 0.9322 | Valid Loss: 1.6457 | Valid Acc: 0.7195\n",
      "Epoch: 27/30 | Train Loss: 0.1622 | Train Acc: 0.9322 | Valid Loss: 1.6563 | Valid Acc: 0.7188\n",
      "Epoch: 28/30 | Train Loss: 0.1609 | Train Acc: 0.9321 | Valid Loss: 1.6739 | Valid Acc: 0.7184\n",
      "Epoch: 29/30 | Train Loss: 0.1575 | Train Acc: 0.9329 | Valid Loss: 1.6806 | Valid Acc: 0.7199\n",
      "Epoch: 30/30 | Train Loss: 0.1556 | Train Acc: 0.9329 | Valid Loss: 1.6835 | Valid Acc: 0.7198\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}.')\n",
    "        best_val_loss = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f47d08-7e31-415b-9bca-99d9e4fb5467",
   "metadata": {},
   "source": [
    "#### Code Source : '딥 러닝 파이토치 교과서 - 입문부터 파인튜닝까지'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Meme_Detection",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
